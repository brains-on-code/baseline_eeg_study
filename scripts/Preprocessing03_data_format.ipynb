{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing 03 - Data Format - Transforming the Raw Data into splitted Data\n",
    "## Partially from replication package (Peitek et al.)\n",
    "\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import mne\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "ZFILL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get all the Participants based on the folders in data/rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "participants = []\n",
    "for _dir, sub_dirs, _files in os.walk(\"./data/rawData\"):\n",
    "    for dir in sub_dirs:\n",
    "        numbers = re.findall(r'\\d+', dir)\n",
    "        participants.append(int(numbers[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Move ICA eeg files back to the raw folder and delete everything in the eeg_tmp folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ica_folder = \"./data/eeg_tmp/ica\"\n",
    "raw_folder = \"./data/eeg_tmp/raw\"\n",
    "\n",
    "# Move ICA eeg files back to the raw folder\n",
    "for participant in tqdm(participants):\n",
    "    participant_folder = \"./data/rawData/Participant\" + str(participant).zfill(ZFILL)\n",
    "    fdt_file_source = ica_folder + \"/eeg_raw_\" + str(participant).zfill(ZFILL) + \".fdt\"\n",
    "    set_file_source = ica_folder + \"/eeg_raw_\" + str(participant).zfill(ZFILL) + \".set\"\n",
    "    fdt_file_destination = participant_folder + \"/eeg_raw_\" + str(participant).zfill(ZFILL) + \".fdt\"\n",
    "    set_file_destination = participant_folder + \"/eeg_raw_\" + str(participant).zfill(ZFILL) + \".set\"\n",
    "    try:\n",
    "        os.rename(fdt_file_source, fdt_file_destination)\n",
    "        os.rename(set_file_source, set_file_destination)\n",
    "    except:\n",
    "        print(\"Participant \" + str(participant) + \" already has the files\")\n",
    "\n",
    "# delete every file in the raw_folder\n",
    "for _dir, _sub_dirs, _files in os.walk(raw_folder):\n",
    "    for file in _files:\n",
    "        os.remove(raw_folder + \"/\" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper functions to transform data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mne.set_log_level(\"WARNING\")\n",
    "\n",
    "# extracts the file name from a path like \"/test/path/file.txt\" and returns \"file\"\n",
    "def to_file_name(path):\n",
    "    file, _ext = os.path.splitext(path)\n",
    "    return file.split(\"\\\\\")[-1]\n",
    "\n",
    "# function to extract numbers from a (x,x) format\n",
    "def two_extractor(value):\n",
    "    two_extractor_compiled = re.compile(\"\\((.*), (.*)\\)\")\n",
    "    pattern = two_extractor_compiled.match(value)\n",
    "    return float(pattern.group(1)), float(pattern.group(2))\n",
    "\n",
    "# Helper to read events from the info field directly; specific to some of our recordings\n",
    "def get_events_from_info(inst):\n",
    "    eventsMNE = []\n",
    "    eventsFromFIF = inst.info[\"events\"]\n",
    "    for event_idx in range(0, len(eventsFromFIF)):\n",
    "        if eventsFromFIF[event_idx].get(\"list\") is not None:\n",
    "            content = eventsFromFIF[event_idx].get(\"list\")\n",
    "            content_list = content.tolist()\n",
    "            content_new = [content_list[2], content_list[1], content_list[0]]\n",
    "            eventsMNE.append(content_new)\n",
    "        elif eventsFromFIF[event_idx].get(\"channels\") is not None:\n",
    "            raise\n",
    "            # content = eventsFromFIF[i].get('channels')\n",
    "        else:\n",
    "            print(\"fiftools: Type of entry #\" + str(event_idx + 1) + \"unknown.\")\n",
    "    eventsMNE = np.array(eventsMNE)\n",
    "    return eventsMNE\n",
    "\n",
    "\n",
    "def load_raw(participant_number, cores=12, digits=1, logging=True,\n",
    "             raw_path=\"./data/rawData/\"):\n",
    "    # setup output for logging\n",
    "    output = sys.stdout\n",
    "    if not logging:\n",
    "        output = open(os.devnull, 'w')\n",
    "\n",
    "    print(\"(01/09) Construct Paths\", file=output, flush=True)\n",
    "    # setup paths for loading\n",
    "    participant_folder = raw_path + \"Participant\" + str(participant_number).zfill(digits) + \"/\"\n",
    "    eye_tracking_path = participant_folder + \"EyeTracking.csv\"\n",
    "    eeg_path = participant_folder + \"eeg_raw.fif\"\n",
    "    eeg_set_path = participant_folder + \"eeg_raw_\" + str(participant_number).zfill(digits) + \".set\"\n",
    "    task_answers_path = participant_folder + \"Task_Answers.csv\"\n",
    "    question_path = \"./data/Questions/Questions\" + str(participant_number).zfill(digits) + \".xlsx\"\n",
    "    hashs_path = participant_folder + \"Hashs.csv\"\n",
    "\n",
    "    print(\"(02/09) Read Eye Tracker Data\", file=output, flush=True)\n",
    "    # read tracker data\n",
    "    df_eye_tracking = pd.read_csv(eye_tracking_path, header=None, sep=\";\")\n",
    "\n",
    "    # get type for parallel processing\n",
    "    meta_type = dd.utils.make_meta(0.0)\n",
    "\n",
    "    # partition dataframe for parallel work\n",
    "    ddf_eye_tracking = dd.from_pandas(df_eye_tracking, npartitions=cores)\n",
    "\n",
    "    print(\"(03/09) Transform Eye Tracker Data\", file=output, flush=True)\n",
    "    # extract the data from the eye-tracking csv to numbers and rename the columns\n",
    "    df_0 = pd.DataFrame(ddf_eye_tracking[0].compute().transpose().tolist(), columns=[\"l_valid\"])\n",
    "    df_1 = pd.DataFrame(\n",
    "        ddf_eye_tracking.apply(lambda x: two_extractor(x[1]), meta=meta_type, axis=1).compute().transpose().tolist(),\n",
    "        columns=[\"l_display_x\", \"l_display_y\"], )\n",
    "    df_2 = pd.DataFrame(ddf_eye_tracking[2].compute().transpose().tolist(), columns=[\"l_pupil_diameter\"])\n",
    "    df_3 = pd.DataFrame(ddf_eye_tracking[3].compute().transpose().tolist(), columns=[\"r_valid\"])\n",
    "    df_4 = pd.DataFrame(\n",
    "        ddf_eye_tracking.apply(lambda x: two_extractor(x[4]), meta=meta_type, axis=1).compute().transpose().tolist(),\n",
    "        columns=[\"r_display_x\", \"r_display_y\"], )\n",
    "    df_5 = pd.DataFrame(ddf_eye_tracking[5].compute().transpose().tolist(), columns=[\"r_pupil_diameter\"])\n",
    "    df_6 = pd.DataFrame(ddf_eye_tracking[6].compute().transpose().tolist(), columns=[\"time\"])\n",
    "\n",
    "    # remove ddf_eye_tracking to save a bit of ram\n",
    "    del ddf_eye_tracking\n",
    "\n",
    "    # concat the dataframes to one eyetracking dataframe\n",
    "    df_eye_tracking = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6], axis=1)\n",
    "\n",
    "    print(\"(04/09) Normalize Eye Tracker Time\", file=output, flush=True)\n",
    "    # normalize the time to seconds\n",
    "    t_0 = df_eye_tracking[\"time\"][0]\n",
    "    df_eye_tracking[\"time\"] = (df_eye_tracking[\"time\"].astype(float) - t_0) / 1000000.0\n",
    "\n",
    "    print(\"(05/09) Read EEG Data\", file=output, flush=True)\n",
    "    # read the eeg data and scale it\n",
    "    raw = mne.io.read_raw_fif(fname=eeg_path, preload=True)\n",
    "    raw_set = mne.io.read_raw_eeglab(eeg_set_path, preload=True)\n",
    "\n",
    "    print(\"(06/09) Construct Events from EEG Data\", file=output, flush=True)\n",
    "    # get the time of the events in seconds\n",
    "    sampling_rate = raw.info[\"sfreq\"]\n",
    "    events = get_events_from_info(raw)\n",
    "    event_ids = events[:, 2]\n",
    "    indices_events = events[:, 0]\n",
    "    t_events = event_ids / sampling_rate\n",
    "\n",
    "    # save the event times in a dataframe for better handling\n",
    "    columns = [\n",
    "        \"Baseline\",\n",
    "        \"BaselineTask\",\n",
    "        \"BaselineHash\",\n",
    "        \"BaselineStart\",\n",
    "        \"BaselineStop\",\n",
    "        \"BaselineCorrectAnswer\",\n",
    "        \"BaselineSkipped\",\n",
    "        \"Snippet\",\n",
    "        \"SnippetHash\",\n",
    "        \"SnippetStart\",\n",
    "        \"SnippetStop\",\n",
    "        \"SnippetCorrectAnswer\",\n",
    "        \"SnippetSkipped\",\n",
    "    ]\n",
    "    df_time = pd.DataFrame([], columns=columns)\n",
    "    i = 0\n",
    "    while i < len(t_events):\n",
    "        df_time = df_time.append(pd.DataFrame([[None, None, indices_events[i + 2], t_events[i + 2], t_events[i + 3], None, None, None, indices_events[i + 6], t_events[i + 6], t_events[i + 7], None, None]], columns=columns, ))\n",
    "        i += 9\n",
    "    df_time = df_time.reset_index(drop=True)\n",
    "\n",
    "    print(\"(07/09) Get Snippet and Baseline for Hash\", file=output, flush=True)\n",
    "    # read the data from the psychopy csv file\n",
    "    df_hash = pd.read_csv(hashs_path)\n",
    "    for index, row in df_time.iterrows():\n",
    "        baseline_path = str(list(df_hash.loc[df_hash['hash'] == row[\"BaselineHash\"], \"task\"])[0])\n",
    "        if \"Text\" in baseline_path:\n",
    "            baseline_type = \"Text\"\n",
    "        elif \"Math\" in baseline_path:\n",
    "            baseline_type = \"Math\"\n",
    "        elif \"Matrix\" in baseline_path:\n",
    "            baseline_type = \"Matrix\"\n",
    "        else:\n",
    "            baseline_type = \"Rest\"\n",
    "        df_time.loc[df_time['BaselineHash'] == row[\"BaselineHash\"], 'BaselineTask'] = to_file_name(baseline_path)\n",
    "        df_time.loc[df_time['BaselineHash'] == row[\"BaselineHash\"], 'Baseline'] = baseline_type\n",
    "        df_time.loc[df_time['SnippetHash'] == row[\"SnippetHash\"], 'Snippet'] = to_file_name(list(df_hash.loc[df_hash['hash'] == row[\"SnippetHash\"], \"task\"])[0])\n",
    "\n",
    "    print(\"(08/09) Transform PsychoPy Data\", file=output, flush=True)\n",
    "    df_questions = pd.read_excel(question_path)\n",
    "    df_task_answer = pd.read_csv(task_answers_path)\n",
    "\n",
    "    for index, row in df_time.iterrows():\n",
    "        if row[\"Baseline\"] == \"Rest\":\n",
    "            row[\"BaselineCorrectAnswer\"] = True\n",
    "            row[\"BaselineSkipped\"] = False\n",
    "        else:\n",
    "            question_baseline_row = df_questions[df_questions[\"QuestionImage\"].str.contains(row[\"BaselineTask\"])].iloc[0]\n",
    "            task_baseline_answer_row = df_task_answer[df_task_answer[\"task\"] == question_baseline_row[\"Baseline_name\"]].iloc[0]\n",
    "            row[\"BaselineCorrectAnswer\"] = question_baseline_row[\"correct_answer\"] == task_baseline_answer_row[\"answer\"]\n",
    "            if task_baseline_answer_row[\"answer\"] == 'k':\n",
    "                row[\"BaselineSkipped\"] = True\n",
    "            else:\n",
    "                row[\"BaselineSkipped\"] = False\n",
    "        question_snippet_row = df_questions[df_questions[\"ProgrammingQuestion\"].str.contains(row[\"Snippet\"])].iloc[0]\n",
    "        task_snippet_row = df_task_answer[df_task_answer[\"task\"] == question_snippet_row[\"Pr_task_name\"]].iloc[0]\n",
    "        row[\"SnippetCorrectAnswer\"] = question_snippet_row[\"Pr_correct_answer\"] == task_snippet_row[\"answer\"]\n",
    "        if task_snippet_row[\"answer\"] == 'k':\n",
    "            row[\"SnippetSkipped\"] = True\n",
    "        else:\n",
    "            row[\"SnippetSkipped\"] = False\n",
    "\n",
    "    print(\"(09/09) Transform All Data to Dictionary\", file=output, flush=True)\n",
    "    # store all the data in a dictionary for better handling. split everything up by snippet\n",
    "    result = {}\n",
    "    # iterate for every snippet to set the data\n",
    "    for index, row in df_time.iterrows():\n",
    "        current = {\"Code\": {\"EyeTracking\": None, \"EEG\": None, \"Time\": {\"Start\": None, \"Stop\": None, }, \"Answer\": None, \"Skipped\": None, },\n",
    "                   \"Baseline\": {\"Type\": None,\"Task\": None,\"EyeTracking\": None, \"EEG\": None, \"Time\": {\"Start\": None, \"Stop\": None, }, \"Answer\": None, \"Skipped\": None, },}\n",
    "\n",
    "        # add data for code\n",
    "        current[\"Code\"][\"EyeTracking\"] = df_eye_tracking[(df_eye_tracking[\"time\"] >= df_time[\"SnippetStart\"][index]) & (df_eye_tracking[\"time\"] < df_time[\"SnippetStop\"][index])]\n",
    "        current[\"Code\"][\"EEG\"] = raw_set.copy().crop(df_time[\"SnippetStart\"][index], df_time[\"SnippetStop\"][index])\n",
    "        current[\"Code\"][\"Time\"][\"Start\"] = df_time[\"SnippetStart\"][index]\n",
    "        current[\"Code\"][\"Time\"][\"Stop\"] = df_time[\"SnippetStop\"][index]\n",
    "        current[\"Code\"][\"Answer\"] = df_time[\"SnippetCorrectAnswer\"][index]\n",
    "        current[\"Code\"][\"Skipped\"] = df_time[\"SnippetSkipped\"][index]\n",
    "\n",
    "        current[\"Baseline\"][\"EyeTracking\"] = df_eye_tracking[(df_eye_tracking[\"time\"] >= df_time[\"BaselineStart\"][index]) & (df_eye_tracking[\"time\"] < df_time[\"BaselineStop\"][index])]\n",
    "        current[\"Baseline\"][\"EEG\"] = raw_set.copy().crop(df_time[\"BaselineStart\"][index], df_time[\"BaselineStop\"][index])\n",
    "        current[\"Baseline\"][\"Time\"][\"Start\"] = df_time[\"BaselineStart\"][index]\n",
    "        current[\"Baseline\"][\"Time\"][\"Stop\"] = df_time[\"BaselineStop\"][index]\n",
    "        current[\"Baseline\"][\"Answer\"] = df_time[\"BaselineCorrectAnswer\"][index]\n",
    "        current[\"Baseline\"][\"Skipped\"] = df_time[\"BaselineSkipped\"][index]\n",
    "        current[\"Baseline\"][\"Type\"] = df_time[\"Baseline\"][index]\n",
    "        current[\"Baseline\"][\"Task\"] = df_time[\"BaselineTask\"][index]\n",
    "\n",
    "        result[row[\"Snippet\"]] = current\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transform all the Data into splitted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = [\"Participant\",\"Baseline\",\"BaselineTask\",\"BaselineStartTime\",\"BaselineEndTime\",\"BaselineEyetracking\",\"BaselineEEG\",\"Algorithm\",\"ProgramStartTime\",\"ProgramEndTime\",\"ProgramEyetracking\",\"ProgramEEG\"]\n",
    "\n",
    "def rescale(data):\n",
    "    # Scaling factor (to obtain values in [V], depends on device and settings etc.)\n",
    "    scaling_factor = 1e-8\n",
    "    return scaling_factor * data\n",
    "\n",
    "# Iterate over all participants\n",
    "for participant in tqdm(participants):\n",
    "    print(\"-----------------------------------------------------------------------------------------\")\n",
    "    print(\"Participant \" + str(participant))\n",
    "\n",
    "    # Check if folder exists\n",
    "    if not os.path.exists(\"./data/filteredData/Participant\" + str(participant).zfill(ZFILL)):\n",
    "        os.makedirs(\"./data/filteredData/Participant\" + str(participant).zfill(ZFILL))\n",
    "\n",
    "    if os.path.exists(\"./data/filteredData/Participant\" + str(participant).zfill(ZFILL) + \"/filtered_data.csv\"):\n",
    "        print(\"Skipped: Already processed\")\n",
    "        continue\n",
    "\n",
    "    df_filtered_part = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Load in Raw Data from Input folder\n",
    "    data = load_raw(participant, cores=24, logging=True)\n",
    "    folder_prev = \"./data/filteredData/Participant\" + str(participant).zfill(ZFILL) + \"/\"\n",
    "\n",
    "    # save the raw data into split data for task/input/output\n",
    "    for algorithm in data.keys():\n",
    "        # Get the start time, end time and answer for baseline\n",
    "        baseline = data[algorithm][\"Baseline\"][\"Type\"]\n",
    "        baseline_task = data[algorithm][\"Baseline\"][\"Task\"]\n",
    "        baseline_start = data[algorithm][\"Baseline\"][\"Time\"][\"Start\"]\n",
    "        baseline_end = data[algorithm][\"Baseline\"][\"Time\"][\"Stop\"]\n",
    "        baseline_answer = data[algorithm][\"Baseline\"][\"Answer\"]\n",
    "        baseline_skipped = data[algorithm][\"Baseline\"][\"Skipped\"]\n",
    "\n",
    "        # Save baseline eeg to file\n",
    "        baseline_eeg = data[algorithm][\"Baseline\"][\"EEG\"]\n",
    "        baseline_eeg.apply_function(rescale, picks=['eeg'])\n",
    "        baseline_eeg.save(folder_prev + algorithm + \"baseline_eeg_raw.fif\",overwrite=True)\n",
    "        baseline_eeg = folder_prev + algorithm + \"baseline_eeg_raw.fif\"\n",
    "\n",
    "        # Save baseline eyetracking to file\n",
    "        baseline_eyetracking = data[algorithm][\"Baseline\"][\"EyeTracking\"]\n",
    "        baseline_eyetracking.to_csv(folder_prev + algorithm + \"baseline_eyetracking_raw.csv\", index=False)\n",
    "        baseline_eyetracking = folder_prev + algorithm + \"baseline_eyetracking_raw.csv\"\n",
    "\n",
    "        # Get the start time, end time and answer for code\n",
    "        code_start = data[algorithm][\"Code\"][\"Time\"][\"Start\"]\n",
    "        code_end = data[algorithm][\"Code\"][\"Time\"][\"Stop\"]\n",
    "        code_answer = data[algorithm][\"Code\"][\"Answer\"]\n",
    "        code_skipped = data[algorithm][\"Code\"][\"Skipped\"]\n",
    "\n",
    "        # Save code eeg to file\n",
    "        code_eeg = data[algorithm][\"Code\"][\"EEG\"]\n",
    "        code_eeg.apply_function(rescale, picks=['eeg'])\n",
    "        code_eeg.save(folder_prev + algorithm + \"code_eeg_raw.fif\", overwrite=True)\n",
    "        code_eeg = folder_prev + algorithm + \"code_eeg_raw.fif\"\n",
    "\n",
    "        # Save code eyetracking to file\n",
    "        code_eyetracking = data[algorithm][\"Code\"][\"EyeTracking\"]\n",
    "        code_eyetracking.to_csv(folder_prev + algorithm + \"code_eyetracking_raw.csv\", index=False)\n",
    "        code_eyetracking = folder_prev + algorithm + \"code_eyetracking_raw.csv\"\n",
    "\n",
    "        # append the data to the dataframe\n",
    "        df_filtered_part = df_filtered_part.append({\n",
    "            \"Participant\": participant,\n",
    "            \"Baseline\": baseline,\n",
    "            \"BaselineTask\": baseline_task,\n",
    "            \"BaselineStartTime\": baseline_start,\n",
    "            \"BaselineEndTime\": baseline_end,\n",
    "            \"BaselineEyetracking\": baseline_eyetracking,\n",
    "            \"BaselineEEG\": baseline_eeg,\n",
    "            \"BaselineCorrect\": baseline_answer,\n",
    "            \"BaselineSkipped\": baseline_skipped,\n",
    "            \"Algorithm\": algorithm,\n",
    "            \"ProgramStartTime\": code_start,\n",
    "            \"ProgramEndTime\": code_end,\n",
    "            \"ProgramEyetracking\": code_eyetracking,\n",
    "            \"ProgramEEG\": code_eeg,\n",
    "            \"ProgramCorrect\": code_answer,\n",
    "            \"ProgramSkipped\": code_skipped,\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    df_filtered_part.to_csv(\"./data/filteredData/Participant\" + str(participant).zfill(ZFILL) + \"/filtered_data.csv\", index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = [\"Participant\",\"Baseline\",\"BaselineTask\",\"BaselineStartTime\",\"BaselineEndTime\",\"BaselineEyetracking\",\"BaselineEEG\",\"Algorithm\",\"ProgramStartTime\",\"ProgramEndTime\",\"ProgramEyetracking\",\"ProgramEEG\"]\n",
    "df_filtered = pd.DataFrame(columns=columns)\n",
    "\n",
    "for participant in tqdm(participants):\n",
    "    df_filtered_part = pd.read_csv(\"./data/filteredData/Participant\" + str(participant).zfill(ZFILL) + \"/filtered_data.csv\")\n",
    "    df_filtered = pd.concat([df_filtered, df_filtered_part], ignore_index=True)\n",
    "\n",
    "df_filtered.to_csv(\"./data/filteredData/filtered_data.csv\", index=False)\n",
    "df_filtered"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}